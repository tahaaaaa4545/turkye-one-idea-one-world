{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "385d10d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean dataset shape: (308, 23)\n",
      "Minimum drift: 0.4\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "df[\"Max drift mm\"] = pd.to_numeric(df[\"Max drift mm\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "df = df[df[\"Max drift mm\"].notna()]\n",
    "df = df[df[\"Max drift mm\"] >= 0].reset_index(drop=True)\n",
    "\n",
    "print(\"Clean dataset shape:\", df.shape)\n",
    "print(\"Minimum drift:\", df[\"Max drift mm\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "874c35cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "df = df[\n",
    "    (df[\"Max drift mm\"].notna()) &   \n",
    "    (df[\"Max drift mm\"] >= 0) &      \n",
    "    (np.isfinite(df[\"Max drift mm\"])) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "046e57dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-22 14:57:16,495] A new study created in memory with name: no-name-6d15f8dc-8cec-4df1-afc7-4e2f47e3cc27\n",
      "[I 2026-02-22 14:57:18,082] Trial 0 finished with value: 0.06578449584418117 and parameters: {'n_estimators': 597, 'learning_rate': 0.011738748405380507, 'max_depth': 5, 'subsample': 0.7785087173711276, 'colsample_bytree': 0.795226007993106, 'reg_alpha': 0.8911627661581074, 'reg_lambda': 0.5118093621661106}. Best is trial 0 with value: 0.06578449584418117.\n",
      "[I 2026-02-22 14:57:20,319] Trial 1 finished with value: 0.04808377875191815 and parameters: {'n_estimators': 515, 'learning_rate': 0.021723315135615987, 'max_depth': 8, 'subsample': 0.8370317095759701, 'colsample_bytree': 0.789329938291928, 'reg_alpha': 0.5211910487206577, 'reg_lambda': 0.25282870202357044}. Best is trial 1 with value: 0.04808377875191815.\n",
      "[I 2026-02-22 14:57:23,674] Trial 2 finished with value: 0.04236251947971315 and parameters: {'n_estimators': 1081, 'learning_rate': 0.024212882605799627, 'max_depth': 6, 'subsample': 0.753914463087154, 'colsample_bytree': 0.8247320605124904, 'reg_alpha': 0.2910787881464899, 'reg_lambda': 0.06443491828556347}. Best is trial 2 with value: 0.04236251947971315.\n",
      "[I 2026-02-22 14:57:29,762] Trial 3 finished with value: 0.04150725022199085 and parameters: {'n_estimators': 1842, 'learning_rate': 0.029848466495414276, 'max_depth': 7, 'subsample': 0.9283159349222045, 'colsample_bytree': 0.8540339707001499, 'reg_alpha': 0.9333376228859666, 'reg_lambda': 0.2850256735468011}. Best is trial 3 with value: 0.04150725022199085.\n",
      "[I 2026-02-22 14:57:34,199] Trial 4 finished with value: 0.0443140596304788 and parameters: {'n_estimators': 1151, 'learning_rate': 0.016184029965807964, 'max_depth': 7, 'subsample': 0.7579359360863548, 'colsample_bytree': 0.9287705937285302, 'reg_alpha': 0.727547075225503, 'reg_lambda': 1.8905451756931666}. Best is trial 3 with value: 0.04150725022199085.\n",
      "[I 2026-02-22 14:57:39,961] Trial 5 finished with value: 0.041820468259797454 and parameters: {'n_estimators': 1738, 'learning_rate': 0.04276268158092517, 'max_depth': 10, 'subsample': 0.8960314895208346, 'colsample_bytree': 0.7164772063747221, 'reg_alpha': 0.8804761826550089, 'reg_lambda': 0.6004677738667641}. Best is trial 3 with value: 0.04150725022199085.\n",
      "[I 2026-02-22 14:57:41,717] Trial 6 finished with value: 0.07436007643460135 and parameters: {'n_estimators': 1179, 'learning_rate': 0.012933768062121213, 'max_depth': 3, 'subsample': 0.7853818003197273, 'colsample_bytree': 0.8012098171247276, 'reg_alpha': 0.798934030632176, 'reg_lambda': 1.6996278719151747}. Best is trial 3 with value: 0.04150725022199085.\n",
      "[I 2026-02-22 14:57:44,896] Trial 7 finished with value: 0.054219277065525456 and parameters: {'n_estimators': 1619, 'learning_rate': 0.014361432344457113, 'max_depth': 4, 'subsample': 0.9581608350029365, 'colsample_bytree': 0.7307810694972899, 'reg_alpha': 0.026452747144532607, 'reg_lambda': 1.098877677884293}. Best is trial 3 with value: 0.04150725022199085.\n",
      "[I 2026-02-22 14:57:53,332] Trial 8 finished with value: 0.04233922126445373 and parameters: {'n_estimators': 1201, 'learning_rate': 0.009000541973489843, 'max_depth': 10, 'subsample': 0.7381595174268306, 'colsample_bytree': 0.9732706246460128, 'reg_alpha': 0.07386445788863527, 'reg_lambda': 1.2555989699024768}. Best is trial 3 with value: 0.04150725022199085.\n",
      "[I 2026-02-22 14:57:58,889] Trial 9 finished with value: 0.04567919803182077 and parameters: {'n_estimators': 1974, 'learning_rate': 0.009401711152819053, 'max_depth': 6, 'subsample': 0.964651238336207, 'colsample_bytree': 0.8021405748285364, 'reg_alpha': 0.05857848828216006, 'reg_lambda': 1.1309204212766168}. Best is trial 3 with value: 0.04150725022199085.\n",
      "[I 2026-02-22 14:58:04,291] Trial 10 finished with value: 0.0397567289771265 and parameters: {'n_estimators': 1588, 'learning_rate': 0.03746424695248267, 'max_depth': 8, 'subsample': 0.8834412142841067, 'colsample_bytree': 0.8849062370727565, 'reg_alpha': 0.5299895667134931, 'reg_lambda': 0.6380315345193177}. Best is trial 10 with value: 0.0397567289771265.\n",
      "[I 2026-02-22 14:58:09,852] Trial 11 finished with value: 0.040152818673311955 and parameters: {'n_estimators': 1599, 'learning_rate': 0.03930697321274593, 'max_depth': 8, 'subsample': 0.9060473520799623, 'colsample_bytree': 0.8968231942035667, 'reg_alpha': 0.5941059276693454, 'reg_lambda': 0.6724405556574173}. Best is trial 10 with value: 0.0397567289771265.\n",
      "[I 2026-02-22 14:58:15,811] Trial 12 finished with value: 0.03997627492786124 and parameters: {'n_estimators': 1529, 'learning_rate': 0.042009982555016534, 'max_depth': 9, 'subsample': 0.8677318211092984, 'colsample_bytree': 0.8920682873893995, 'reg_alpha': 0.5111493684420428, 'reg_lambda': 0.7552028846308626}. Best is trial 10 with value: 0.0397567289771265.\n",
      "[I 2026-02-22 14:58:21,625] Trial 13 finished with value: 0.03945447967308298 and parameters: {'n_estimators': 1461, 'learning_rate': 0.04970382523609582, 'max_depth': 9, 'subsample': 0.8553187618935606, 'colsample_bytree': 0.9003457971186083, 'reg_alpha': 0.3480253859239504, 'reg_lambda': 0.8054286519739375}. Best is trial 13 with value: 0.03945447967308298.\n",
      "[I 2026-02-22 14:58:27,536] Trial 14 finished with value: 0.03925318017431793 and parameters: {'n_estimators': 1382, 'learning_rate': 0.03384905363590728, 'max_depth': 9, 'subsample': 0.8369351022794613, 'colsample_bytree': 0.9651596502806727, 'reg_alpha': 0.3168118337505849, 'reg_lambda': 1.4607624199230669}. Best is trial 14 with value: 0.03925318017431793.\n",
      "[I 2026-02-22 14:58:33,255] Trial 15 finished with value: 0.03855018237983526 and parameters: {'n_estimators': 1383, 'learning_rate': 0.04841368459259087, 'max_depth': 9, 'subsample': 0.8250781047429274, 'colsample_bytree': 0.99268584006004, 'reg_alpha': 0.2886238459940974, 'reg_lambda': 1.534961010283237}. Best is trial 15 with value: 0.03855018237983526.\n",
      "[I 2026-02-22 14:58:37,212] Trial 16 finished with value: 0.03952444758027672 and parameters: {'n_estimators': 876, 'learning_rate': 0.03163618941029782, 'max_depth': 9, 'subsample': 0.7005227001526775, 'colsample_bytree': 0.9897741925295285, 'reg_alpha': 0.2734967630703644, 'reg_lambda': 1.4656991750744655}. Best is trial 15 with value: 0.03855018237983526.\n",
      "[I 2026-02-22 14:58:43,368] Trial 17 finished with value: 0.039633212385205306 and parameters: {'n_estimators': 1381, 'learning_rate': 0.04935794320761211, 'max_depth': 10, 'subsample': 0.8262308679383601, 'colsample_bytree': 0.9551790471063291, 'reg_alpha': 0.18511130968106176, 'reg_lambda': 1.4507131883896773}. Best is trial 15 with value: 0.03855018237983526.\n",
      "[I 2026-02-22 14:58:47,609] Trial 18 finished with value: 0.03977563701816438 and parameters: {'n_estimators': 968, 'learning_rate': 0.03427337694736672, 'max_depth': 9, 'subsample': 0.7954047189928086, 'colsample_bytree': 0.9424743814005998, 'reg_alpha': 0.41908450986701173, 'reg_lambda': 1.6429606811329798}. Best is trial 15 with value: 0.03855018237983526.\n",
      "[I 2026-02-22 14:58:53,750] Trial 19 finished with value: 0.03827792167935941 and parameters: {'n_estimators': 1373, 'learning_rate': 0.04435660778661013, 'max_depth': 8, 'subsample': 0.8118477067071157, 'colsample_bytree': 0.9952684283891338, 'reg_alpha': 0.15878206702219985, 'reg_lambda': 1.3487277513742564}. Best is trial 19 with value: 0.03827792167935941.\n",
      "[I 2026-02-22 14:58:53,755] A new study created in memory with name: no-name-7368ac99-8c5c-4fd6-a74e-74a14cadd5e6\n",
      "[I 2026-02-22 14:58:57,916] Trial 0 finished with value: 0.0537103100080161 and parameters: {'n_estimators': 1881, 'learning_rate': 0.014672063176772884, 'max_depth': 4, 'subsample': 0.9117448653503188, 'colsample_bytree': 0.7949151744244151, 'reg_alpha': 0.5773329186009523, 'reg_lambda': 1.4801027692134006}. Best is trial 0 with value: 0.0537103100080161.\n",
      "[I 2026-02-22 14:59:00,156] Trial 1 finished with value: 0.04478521485456903 and parameters: {'n_estimators': 1064, 'learning_rate': 0.03418668443060791, 'max_depth': 5, 'subsample': 0.8590500280796887, 'colsample_bytree': 0.7224115937227882, 'reg_alpha': 0.6919878439561233, 'reg_lambda': 1.533848845888216}. Best is trial 1 with value: 0.04478521485456903.\n",
      "[I 2026-02-22 14:59:03,135] Trial 2 finished with value: 0.055906413096397115 and parameters: {'n_estimators': 1003, 'learning_rate': 0.008929544040559907, 'max_depth': 5, 'subsample': 0.8544711725983661, 'colsample_bytree': 0.9781629225734241, 'reg_alpha': 0.4688564693362496, 'reg_lambda': 0.8288495969521952}. Best is trial 1 with value: 0.04478521485456903.\n",
      "[I 2026-02-22 14:59:04,447] Trial 3 finished with value: 0.06029515738142887 and parameters: {'n_estimators': 833, 'learning_rate': 0.04403424460243077, 'max_depth': 3, 'subsample': 0.9372342171204124, 'colsample_bytree': 0.9579970155777655, 'reg_alpha': 0.24633486642367097, 'reg_lambda': 0.8034279908757709}. Best is trial 1 with value: 0.04478521485456903.\n",
      "[I 2026-02-22 14:59:08,054] Trial 4 finished with value: 0.04635802606365557 and parameters: {'n_estimators': 1398, 'learning_rate': 0.01017790115368658, 'max_depth': 6, 'subsample': 0.8026782097945745, 'colsample_bytree': 0.9046083755452012, 'reg_alpha': 0.6636830582216606, 'reg_lambda': 0.5188202715373267}. Best is trial 1 with value: 0.04478521485456903.\n",
      "[I 2026-02-22 14:59:12,589] Trial 5 finished with value: 0.039184116631158145 and parameters: {'n_estimators': 1224, 'learning_rate': 0.03913789054630419, 'max_depth': 8, 'subsample': 0.9234673370098074, 'colsample_bytree': 0.9154903617179599, 'reg_alpha': 0.259192022232287, 'reg_lambda': 0.7883102219549176}. Best is trial 5 with value: 0.039184116631158145.\n",
      "[I 2026-02-22 14:59:16,047] Trial 6 finished with value: 0.043804663685871464 and parameters: {'n_estimators': 1963, 'learning_rate': 0.035170057331803714, 'max_depth': 4, 'subsample': 0.7601491718604567, 'colsample_bytree': 0.8722395674021519, 'reg_alpha': 0.8021467983472274, 'reg_lambda': 0.24130989483225918}. Best is trial 5 with value: 0.039184116631158145.\n",
      "[I 2026-02-22 14:59:22,815] Trial 7 finished with value: 0.039125599134814275 and parameters: {'n_estimators': 1995, 'learning_rate': 0.03463795596618697, 'max_depth': 10, 'subsample': 0.8306653428713144, 'colsample_bytree': 0.8336704009574465, 'reg_alpha': 0.5248421466520535, 'reg_lambda': 1.3714085802789173}. Best is trial 7 with value: 0.039125599134814275.\n",
      "[I 2026-02-22 14:59:28,471] Trial 8 finished with value: 0.0381614350183465 and parameters: {'n_estimators': 1844, 'learning_rate': 0.04750645710017525, 'max_depth': 8, 'subsample': 0.8184118170976681, 'colsample_bytree': 0.8663986148647458, 'reg_alpha': 0.38538954143267934, 'reg_lambda': 0.8629266826335575}. Best is trial 8 with value: 0.0381614350183465.\n",
      "[I 2026-02-22 14:59:32,454] Trial 9 finished with value: 0.0411506178587682 and parameters: {'n_estimators': 1416, 'learning_rate': 0.04352332662062163, 'max_depth': 6, 'subsample': 0.7395773885445274, 'colsample_bytree': 0.7419858949871246, 'reg_alpha': 0.6912508973270518, 'reg_lambda': 1.1680893856161876}. Best is trial 8 with value: 0.0381614350183465.\n",
      "[I 2026-02-22 14:59:35,119] Trial 10 finished with value: 0.041591343981519015 and parameters: {'n_estimators': 562, 'learning_rate': 0.04982849579761252, 'max_depth': 8, 'subsample': 0.979861752685117, 'colsample_bytree': 0.8049046677765807, 'reg_alpha': 0.03818123596166084, 'reg_lambda': 1.9898228532443862}. Best is trial 8 with value: 0.0381614350183465.\n",
      "[I 2026-02-22 14:59:41,373] Trial 11 finished with value: 0.04032400165891495 and parameters: {'n_estimators': 1701, 'learning_rate': 0.023687723619667662, 'max_depth': 10, 'subsample': 0.8123201118091912, 'colsample_bytree': 0.8268176274532764, 'reg_alpha': 0.41864830925076413, 'reg_lambda': 1.306338960426978}. Best is trial 8 with value: 0.0381614350183465.\n",
      "[I 2026-02-22 14:59:47,102] Trial 12 finished with value: 0.04193278701616743 and parameters: {'n_estimators': 1706, 'learning_rate': 0.027119602429887164, 'max_depth': 10, 'subsample': 0.7058929673683423, 'colsample_bytree': 0.860619372975276, 'reg_alpha': 0.9511692562196765, 'reg_lambda': 1.830225479745371}. Best is trial 8 with value: 0.0381614350183465.\n",
      "[I 2026-02-22 14:59:52,205] Trial 13 finished with value: 0.038139485287714874 and parameters: {'n_estimators': 1700, 'learning_rate': 0.04985410347130918, 'max_depth': 8, 'subsample': 0.8104567433110871, 'colsample_bytree': 0.7706190589232684, 'reg_alpha': 0.32454438680732833, 'reg_lambda': 1.1114194278040652}. Best is trial 13 with value: 0.038139485287714874.\n",
      "[I 2026-02-22 14:59:57,243] Trial 14 finished with value: 0.038516324192281175 and parameters: {'n_estimators': 1633, 'learning_rate': 0.04880272743650116, 'max_depth': 8, 'subsample': 0.7758462588909509, 'colsample_bytree': 0.7655761937165148, 'reg_alpha': 0.2975086285482085, 'reg_lambda': 0.04077206565084768}. Best is trial 13 with value: 0.038139485287714874.\n",
      "[I 2026-02-22 15:00:03,917] Trial 15 finished with value: 0.0405021722925589 and parameters: {'n_estimators': 1522, 'learning_rate': 0.042822201830796686, 'max_depth': 8, 'subsample': 0.8706032400177917, 'colsample_bytree': 0.7010010806274503, 'reg_alpha': 0.030862177913293265, 'reg_lambda': 1.0336903633056695}. Best is trial 13 with value: 0.038139485287714874.\n",
      "[I 2026-02-22 15:00:09,215] Trial 16 finished with value: 0.040862294410301835 and parameters: {'n_estimators': 1782, 'learning_rate': 0.02004776665847777, 'max_depth': 7, 'subsample': 0.7889035430781295, 'colsample_bytree': 0.7771009120448804, 'reg_alpha': 0.35130176563173077, 'reg_lambda': 0.5261774743427823}. Best is trial 13 with value: 0.038139485287714874.\n",
      "[I 2026-02-22 15:00:14,963] Trial 17 finished with value: 0.04046891084341556 and parameters: {'n_estimators': 1473, 'learning_rate': 0.04997964044929455, 'max_depth': 9, 'subsample': 0.8854611661884444, 'colsample_bytree': 0.8932410957529716, 'reg_alpha': 0.12805114369327142, 'reg_lambda': 0.47303373888370226}. Best is trial 13 with value: 0.038139485287714874.\n",
      "[I 2026-02-22 15:00:21,008] Trial 18 finished with value: 0.036979341724351314 and parameters: {'n_estimators': 1798, 'learning_rate': 0.038818940003872926, 'max_depth': 7, 'subsample': 0.7346182042739499, 'colsample_bytree': 0.9307983226482325, 'reg_alpha': 0.17573349118111486, 'reg_lambda': 1.6721564699382083}. Best is trial 18 with value: 0.036979341724351314.\n",
      "[I 2026-02-22 15:00:25,134] Trial 19 finished with value: 0.036860413861185576 and parameters: {'n_estimators': 1218, 'learning_rate': 0.03825610856077764, 'max_depth': 7, 'subsample': 0.7149189498812142, 'colsample_bytree': 0.9371375182730216, 'reg_alpha': 0.15797317169100644, 'reg_lambda': 1.6883427877983932}. Best is trial 19 with value: 0.036860413861185576.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 1218, 'learning_rate': 0.03825610856077764, 'max_depth': 7, 'subsample': 0.7149189498812142, 'colsample_bytree': 0.9371375182730216, 'reg_alpha': 0.15797317169100644, 'reg_lambda': 1.6883427877983932}\n",
      "\n",
      "===== Evaluation =====\n",
      "R2 Score: 0.9765\n",
      "MAE: 0.0953\n",
      "RMSE: 0.1353\n",
      "MAPE: 3.69%\n",
      "Accuracy: 96.31%\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 322\n",
      "[LightGBM] [Info] Number of data points in the train set: 2337, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 2.717326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 322\n",
      "[LightGBM] [Info] Number of data points in the train set: 2337, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 2.717326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 322\n",
      "[LightGBM] [Info] Number of data points in the train set: 1869, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 2.723939\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 322\n",
      "[LightGBM] [Info] Number of data points in the train set: 1869, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 2.707082\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 322\n",
      "[LightGBM] [Info] Number of data points in the train set: 1870, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 2.705150\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 322\n",
      "[LightGBM] [Info] Number of data points in the train set: 1870, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 2.730160\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 322\n",
      "[LightGBM] [Info] Number of data points in the train set: 1870, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 2.720295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 322\n",
      "[LightGBM] [Info] Number of data points in the train set: 1869, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 2.723939\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 322\n",
      "[LightGBM] [Info] Number of data points in the train set: 1869, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 2.707082\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 322\n",
      "[LightGBM] [Info] Number of data points in the train set: 1870, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 2.705150\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 322\n",
      "[LightGBM] [Info] Number of data points in the train set: 1870, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 2.730160\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 322\n",
      "[LightGBM] [Info] Number of data points in the train set: 1870, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 2.720295\n",
      "Validation MAPE: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer:  83%|████████▎ | 1936/2337 [22:41<04:42,  1.42it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 158\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# 10. SHAP Explainability\u001b[39;00m\n\u001b[0;32m    157\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(pipeline\u001b[38;5;241m.\u001b[39mpredict, X_train)\n\u001b[1;32m--> 158\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m shap\u001b[38;5;241m.\u001b[39msummary_plot(shap_values, X_train)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# 11. Partial Dependence Plots\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\shap\\explainers\\_exact.py:76\u001b[0m, in \u001b[0;36mExactExplainer.__call__\u001b[1;34m(self, max_evals, main_effects, error_bounds, batch_size, interactions, silent, *args)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Explains the output of model(*args), where args represents one or more parallel iterators.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# we entirely rely on the general call implementation, we override just to remove **kwargs\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# from the function signature\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_effects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmain_effects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minteractions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minteractions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\shap\\explainers\\_explainer.py:267\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[1;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(args))]\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_args \u001b[38;5;129;01min\u001b[39;00m show_progress(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39margs), num_rows, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m explainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent):\n\u001b[1;32m--> 267\u001b[0m     row_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_row\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrow_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_effects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmain_effects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(row_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    272\u001b[0m     output_indices\u001b[38;5;241m.\u001b[39mappend(row_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_indices\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\shap\\explainers\\_exact.py:120\u001b[0m, in \u001b[0;36mExactExplainer.explain_row\u001b[1;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, interactions, silent, *row_args)\u001b[0m\n\u001b[0;32m    117\u001b[0m         extended_delta_indexes[i] \u001b[38;5;241m=\u001b[39m inds[delta_indexes[i]]\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# run the model\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextended_delta_indexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Shapley values\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Care: Need to distinguish between `True` and `1`\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interactions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (interactions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m interactions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    125\u001b[0m \n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m# loop over all the outputs to update the rows\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\shap\\utils\\_masked_model.py:59\u001b[0m, in \u001b[0;36mMaskedModel.__call__\u001b[1;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(masks\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasker, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupports_delta_masking\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 59\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_delta_masking_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# we need to convert from delta masking to a full masking call because we were given a delta masking\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# input but the masker does not support delta masking\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m         full_masks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39msum(masks \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_masker_cols), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\shap\\utils\\_masked_model.py:205\u001b[0m, in \u001b[0;36mMaskedModel._delta_masking_call\u001b[1;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[0;32m    202\u001b[0m     batch_positions[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m batch_positions[i] \u001b[38;5;241m+\u001b[39m num_varying_rows[i]\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# joined_masked_inputs = self._stack_inputs(all_masked_inputs)\u001b[39;00m\n\u001b[1;32m--> 205\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubset_masked_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m _assert_output_input_match(subset_masked_inputs, outputs)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinearize_link \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlink \u001b[38;5;241m!=\u001b[39m links\u001b[38;5;241m.\u001b[39midentity \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linearizing_weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\shap\\models\\_model.py:28\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m---> 28\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     is_tensor \u001b[38;5;241m=\u001b[39m safe_isinstance(out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mif\u001b[39;00m is_tensor \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(out)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py:515\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    514\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[1;32m--> 515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_stacking.py:369\u001b[0m, in \u001b[0;36m_BaseStacking.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict target for X.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \n\u001b[0;32m    350\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03m    Predicted targets.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    368\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_estimator_\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_stacking.py:972\u001b[0m, in \u001b[0;36mStackingRegressor.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the predictions for X for each estimator.\u001b[39;00m\n\u001b[0;32m    960\u001b[0m \n\u001b[0;32m    961\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;124;03m        Prediction outputs for each estimator.\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 972\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_stacking.py:293\u001b[0m, in \u001b[0;36m_BaseStacking._transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Concatenate and return the predictions of the estimators.\"\"\"\u001b[39;00m\n\u001b[0;32m    292\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 293\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(est, meth)(X)\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m est, meth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    297\u001b[0m ]\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concatenate_predictions(X, predictions)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_stacking.py:294\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Concatenate and return the predictions of the estimators.\"\"\"\u001b[39;00m\n\u001b[0;32m    292\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    293\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m est, meth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    297\u001b[0m ]\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concatenate_predictions(X, predictions)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1248\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1248\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1256\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[0;32m   1257\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\core.py:2534\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2530\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ensure_np_dtype\n\u001b[0;32m   2532\u001b[0m     data, _ \u001b[38;5;241m=\u001b[39m _ensure_np_dtype(data, data\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2533\u001b[0m     _check_call(\n\u001b[1;32m-> 2534\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterPredictFromDense\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2535\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2536\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_array_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2537\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2538\u001b[0m \u001b[43m            \u001b[49m\u001b[43mp_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2539\u001b[0m \u001b[43m            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2540\u001b[0m \u001b[43m            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2541\u001b[0m \u001b[43m            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2542\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2543\u001b[0m     )\n\u001b[0;32m   2544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _prediction_output(shape, dims, preds, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, PandasTransformed):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# 2. Load Data\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "target = \"Max drift mm\"\n",
    "selected_features = [\n",
    "    \"Period s\",\n",
    "    \"Number of floors\",\n",
    "    \"PGA g\",\n",
    "    \"Magnitude\",\n",
    "    \"Distance to fault km\",\n",
    "    \"Columns 1-3 I mm4*10^6\"\n",
    "]\n",
    "\n",
    "X = df[selected_features]\n",
    "y = df[target]\n",
    "\n",
    "\n",
    "# Log scaling target\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# 3. Train-Test Split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y_log, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 4. Bayesian Optimization for XGBoost\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 500, 2000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.05),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.7, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 2.0),\n",
    "        \"random_state\": 42,\n",
    "        \"tree_method\": \"hist\"\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_percentage_error(y_valid, preds)\n",
    "\n",
    "study_xgb = optuna.create_study(direction=\"minimize\")\n",
    "study_xgb.optimize(objective_xgb, n_trials=20)\n",
    "\n",
    "best_xgb_params = study_xgb.best_params\n",
    "\n",
    "study_xgb = optuna.create_study(direction=\"minimize\")\n",
    "study_xgb.optimize(objective_xgb, n_trials=20)\n",
    "\n",
    "best_xgb_params = study_xgb.best_params\n",
    "print(\"Best Params:\", best_xgb_params)\n",
    "\n",
    "model = XGBRegressor(\n",
    "    **best_xgb_params,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "r2 = r2_score(y_valid, y_pred)\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "mape = mean_absolute_percentage_error(y_valid, y_pred) * 100\n",
    "accuracy = 100 - mape\n",
    "\n",
    "print(\"\\n===== Evaluation =====\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "# 5. Define Optimized Models\n",
    "\n",
    "xgb1 = XGBRegressor(**best_xgb_params)\n",
    "xgb2 = XGBRegressor(**best_xgb_params)\n",
    "\n",
    "lgb1 = LGBMRegressor(random_state=42)\n",
    "lgb2 = LGBMRegressor(random_state=24)\n",
    "\n",
    "cat = CatBoostRegressor(iterations=1500, depth=8, learning_rate=0.02,\n",
    "                        verbose=0, random_seed=42)\n",
    "\n",
    "# 6. Stacking Regressor\n",
    "\n",
    "stack_model = StackingRegressor(\n",
    "    estimators=[\n",
    "        (\"xgb1\", xgb1),\n",
    "        (\"xgb2\", xgb2),\n",
    "        (\"lgb1\", lgb1),\n",
    "        (\"lgb2\", lgb2),\n",
    "        (\"cat\", cat)\n",
    "    ],\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "\n",
    "\n",
    "# 7. Full Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", stack_model)\n",
    "])\n",
    "\n",
    "\n",
    "# 8. Train Final Model\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 9. Evaluate\n",
    "preds_log = pipeline.predict(X_valid)\n",
    "preds = np.expm1(preds_log)\n",
    "y_true = np.expm1(y_valid)\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_true, preds)\n",
    "print(f\"Validation MAPE: {mape:.4f}\")\n",
    "\n",
    "# 10. SHAP Explainability\n",
    "\n",
    "explainer = shap.Explainer(pipeline.predict, X_train)\n",
    "shap_values = explainer(X_train)\n",
    "shap.summary_plot(shap_values, X_train)\n",
    "\n",
    "\n",
    "# 11. Partial Dependence Plots\n",
    "\n",
    "PartialDependenceDisplay.from_estimator(pipeline, X_train, [0,1,2])\n",
    "plt.show()\n",
    "\n",
    "# 12. Safety Classification\n",
    "\n",
    "def classify_building(drift):\n",
    "    if drift <= 20:\n",
    "        return \"Safe\"\n",
    "    elif drift <= 50:\n",
    "        return \"Warning\"\n",
    "    else:\n",
    "        return \"Dangerous\"\n",
    "\n",
    "\n",
    "# 13. User Input Prediction\n",
    "\n",
    "user_input = {}\n",
    "print(\"Enter building and seismic properties:\")\n",
    "\n",
    "for feature in selected_features:\n",
    "    while True:\n",
    "        try:\n",
    "            user_input[feature] = float(input(f\"{feature}: \"))\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Please enter a numeric value.\")\n",
    "\n",
    "X_user = pd.DataFrame([user_input])\n",
    "\n",
    "pred_log = pipeline.predict(X_user)[0]\n",
    "pred = np.expm1(pred_log)\n",
    "status = classify_building(pred)\n",
    "\n",
    "print(f\"\\nPredicted Drift: {pred:.2f} mm -> {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bba40aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter building and seismic properties:\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease enter a numeric value.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m X_user \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([user_input])\n\u001b[1;32m---> 26\u001b[0m pred_log \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_user\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     27\u001b[0m pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpm1(pred_log)\n\u001b[0;32m     28\u001b[0m status \u001b[38;5;241m=\u001b[39m classify_building(pred)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py:515\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    514\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[1;32m--> 515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_stacking.py:369\u001b[0m, in \u001b[0;36m_BaseStacking.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict target for X.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \n\u001b[0;32m    350\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03m    Predicted targets.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    368\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_base.py:386\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    373\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_base.py:367\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m--> 367\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m], reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:1461\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# 12. Safety Classification\n",
    "\n",
    "def classify_building(drift):\n",
    "    if drift <= 20:\n",
    "        return \"Safe\"\n",
    "    elif drift <= 50:\n",
    "        return \"Warning\"\n",
    "    else:\n",
    "        return \"Dangerous\"\n",
    "\n",
    "\n",
    "# 13. User Input Prediction \n",
    "user_input = {}\n",
    "print(\"Enter building and seismic properties:\")\n",
    "\n",
    "for feature in selected_features:\n",
    "    while True:\n",
    "        try:\n",
    "            user_input[feature] = float(input(f\"{feature}: \"))\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Please enter a numeric value.\")\n",
    "\n",
    "X_user = pd.DataFrame([user_input])\n",
    "\n",
    "pred_log = pipeline.predict(X_user)[0]\n",
    "pred = np.expm1(pred_log)\n",
    "status = classify_building(pred)\n",
    "\n",
    "print(f\"\\nPredicted Drift: {pred:.2f} mm -> {status}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
